# PI_GAN_THZ/config/training_optimization.py
# è®­ç»ƒä¼˜åŒ–é…ç½® - åŸºäºè¯„ä¼°ç»“æœçš„é’ˆå¯¹æ€§æ”¹è¿›

import os
import torch

# ä»åŸé…ç½®ç»§æ‰¿åŸºæœ¬è®¾ç½®
from config.config import *

# =============================================================================
# ä¼˜åŒ–é…ç½® - åŸºäºè¯„ä¼°ç»“æœçš„æ”¹è¿›æ–¹æ¡ˆ
# =============================================================================

# --- 1. å‰å‘ç½‘ç»œä¼˜åŒ– (è§£å†³å…‰è°±é¢„æµ‹RÂ²=0.5018é—®é¢˜) ---
FORWARD_MODEL_OPTIMIZATION = {
    # å¢å¼ºç½‘ç»œå®¹é‡
    'hidden_dims': [128, 256, 512, 1024, 512, 256],  # æ›´æ·±æ›´å®½çš„ç½‘ç»œ
    'dropout_rate': 0.3,                              # é˜²æ­¢è¿‡æ‹Ÿåˆ
    'batch_norm': True,                               # æ‰¹å½’ä¸€åŒ–ç¨³å®šè®­ç»ƒ
    'activation': 'leaky_relu',                       # æ›´å¥½çš„æ¿€æ´»å‡½æ•°
    
    # ä¼˜åŒ–æŸå¤±å‡½æ•°
    'spectrum_loss_weight': 1.0,                      # å…‰è°±é‡å»ºæŸå¤±æƒé‡
    'metrics_loss_weight': 0.8,                       # æŒ‡æ ‡é¢„æµ‹æŸå¤±æƒé‡
    'smoothness_loss_weight': 0.1,                    # å…‰è°±å¹³æ»‘æ€§æŸå¤±
    'physics_loss_weight': 0.2,                       # ç‰©ç†çº¦æŸæŸå¤±
    
    # è®­ç»ƒå‚æ•°
    'learning_rate': 1e-4,                            # é™ä½å­¦ä¹ ç‡
    'epochs': 200,                                    # å¢åŠ è®­ç»ƒè½®æ•°
    'early_stopping_patience': 20,                   # æ—©åœè€å¿ƒ
    'lr_scheduler': 'cosine',                         # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
}

# --- 2. ç”Ÿæˆå™¨ä¼˜åŒ– (è§£å†³å‚æ•°é¢„æµ‹RÂ²=0.5329é—®é¢˜) ---
GENERATOR_OPTIMIZATION = {
    # ç½‘ç»œç»“æ„ä¼˜åŒ–
    'hidden_dims': [512, 1024, 2048, 1024, 512, 256], # æ›´å¼ºçš„è¡¨å¾èƒ½åŠ›
    'residual_blocks': 3,                             # æ®‹å·®è¿æ¥
    'attention_layers': 2,                            # æ³¨æ„åŠ›æœºåˆ¶
    'dropout_rate': 0.2,                              # é€‚åº¦æ­£åˆ™åŒ–
    
    # æŸå¤±å‡½æ•°æ”¹è¿›
    'adversarial_loss_weight': 1.0,                   # å¯¹æŠ—æŸå¤±
    'reconstruction_loss_weight': 10.0,               # é‡å»ºæŸå¤±ï¼ˆæé«˜æƒé‡ï¼‰
    'perceptual_loss_weight': 5.0,                    # æ„ŸçŸ¥æŸå¤±
    'constraint_loss_weight': 2.0,                    # å‚æ•°çº¦æŸæŸå¤±
    
    # è®­ç»ƒç­–ç•¥
    'learning_rate': 2e-4,                            # é€‚ä¸­å­¦ä¹ ç‡
    'beta1': 0.5,                                     # Adamä¼˜åŒ–å™¨å‚æ•°
    'beta2': 0.999,
    'gradient_clip': 1.0,                             # æ¢¯åº¦è£å‰ª
}

# --- 3. åˆ¤åˆ«å™¨ä¼˜åŒ– (è§£å†³åˆ¤åˆ«å‡†ç¡®ç‡=0.6085é—®é¢˜) ---
DISCRIMINATOR_OPTIMIZATION = {
    # ç½‘ç»œç»“æ„
    'hidden_dims': [256, 512, 1024, 512, 256, 128],  # å¹³è¡¡çš„ç½‘ç»œæ·±åº¦
    'spectral_norm': True,                            # è°±å½’ä¸€åŒ–ç¨³å®šè®­ç»ƒ
    'dropout_rate': 0.3,                              # é˜²æ­¢è¿‡æ‹Ÿåˆ
    'leaky_relu_slope': 0.2,                          # LeakyReLUæ–œç‡
    
    # è®­ç»ƒå‚æ•°
    'learning_rate': 1e-4,                            # ç•¥ä½äºç”Ÿæˆå™¨
    'label_smoothing': 0.1,                           # æ ‡ç­¾å¹³æ»‘
    'instance_noise': 0.05,                           # å®ä¾‹å™ªå£°
    
    # æŸå¤±å‡½æ•°
    'loss_type': 'wgan_gp',                           # WGAN-GPæŸå¤±
    'gradient_penalty_weight': 10.0,                  # æ¢¯åº¦æƒ©ç½šæƒé‡
}

# --- 4. å‚æ•°çº¦æŸä¼˜åŒ– (è§£å†³è¿çº¦ç‡87.4%é—®é¢˜) ---
CONSTRAINT_OPTIMIZATION = {
    # ç¡¬çº¦æŸ
    'parameter_clipping': True,                       # å‚æ•°è£å‰ª
    'parameter_ranges': {                             # ä¸¥æ ¼å‚æ•°èŒƒå›´
        'r1': (2.2, 2.8),
        'r2': (2.2, 2.8), 
        'w': (2.2, 2.8),
        'g': (2.2, 2.8)
    },
    
    # è½¯çº¦æŸæŸå¤±
    'range_penalty_weight': 5.0,                      # èŒƒå›´æƒ©ç½šæƒé‡
    'boundary_smoothness': 0.1,                       # è¾¹ç•Œå¹³æ»‘åº¦
    'constraint_activation': 'sigmoid',               # çº¦æŸæ¿€æ´»å‡½æ•°
    
    # ç‰©ç†çº¦æŸ
    'physics_constraint_weight': 3.0,                 # ç‰©ç†çº¦æŸæƒé‡
    'resonance_constraint': True,                     # è°æŒ¯çº¦æŸ
    'causality_constraint': True,                     # å› æœçº¦æŸ
}

# --- 5. è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ– ---
TRAINING_OPTIMIZATION = {
    # æ•°æ®å¢å¼º
    'data_augmentation': {
        'noise_level': 0.05,                          # å™ªå£°å¢å¼º
        'frequency_shift': 0.02,                      # é¢‘ç‡åç§»
        'amplitude_scale': 0.1,                       # å¹…åº¦ç¼©æ”¾
    },
    
    # è®­ç»ƒç­–ç•¥
    'progressive_training': True,                     # æ¸è¿›è®­ç»ƒ
    'curriculum_learning': True,                      # è¯¾ç¨‹å­¦ä¹ 
    'mixed_precision': True,                          # æ··åˆç²¾åº¦
    
    # è¯„ä¼°ç­–ç•¥
    'evaluation_frequency': 10,                      # è¯„ä¼°é¢‘ç‡
    'save_best_model': True,                          # ä¿å­˜æœ€ä¼˜æ¨¡å‹
    'validation_split': 0.2,                         # éªŒè¯é›†æ¯”ä¾‹
    
    # è¶…å‚æ•°è°ƒåº¦
    'warmup_epochs': 10,                              # é¢„çƒ­è½®æ•°
    'cosine_annealing': True,                         # ä½™å¼¦é€€ç«
    'weight_decay': 1e-4,                             # æƒé‡è¡°å‡
}

# --- 6. æŸå¤±å‡½æ•°æƒé‡ä¼˜åŒ– ---
LOSS_WEIGHTS = {
    # åŸºç¡€æŸå¤±
    'adversarial_loss': 1.0,                          # å¯¹æŠ—æŸå¤±
    'reconstruction_loss': 10.0,                      # é‡å»ºæŸå¤±
    'forward_consistency_loss': 5.0,                  # å‰å‘ä¸€è‡´æ€§æŸå¤±
    
    # çº¦æŸæŸå¤±
    'parameter_constraint_loss': 3.0,                 # å‚æ•°çº¦æŸæŸå¤±
    'physics_constraint_loss': 2.0,                   # ç‰©ç†çº¦æŸæŸå¤±
    'smoothness_loss': 1.0,                           # å¹³æ»‘æ€§æŸå¤±
    
    # æ­£åˆ™åŒ–æŸå¤±
    'diversity_loss': 0.5,                            # å¤šæ ·æ€§æŸå¤±
    'sparsity_loss': 0.1,                             # ç¨€ç–æ€§æŸå¤±
    'stability_loss': 1.0,                            # ç¨³å®šæ€§æŸå¤±
}

# --- 7. æ¨¡å‹æ¶æ„ä¼˜åŒ– ---
MODEL_ARCHITECTURE = {
    'generator': {
        'base_channels': 64,
        'max_channels': 512,
        'num_residual_blocks': 6,
        'use_attention': True,
        'attention_heads': 8,
        'use_self_attention': True,
    },
    
    'discriminator': {
        'base_channels': 32,
        'max_channels': 256,
        'num_layers': 6,
        'use_spectral_norm': True,
        'use_gradient_penalty': True,
    },
    
    'forward_model': {
        'hidden_layers': [128, 256, 512, 1024, 512, 256, 128],
        'use_residual': True,
        'use_batch_norm': True,
        'use_dropout': True,
    }
}

# --- 8. ä¼˜åŒ–å™¨é…ç½® ---
OPTIMIZER_CONFIG = {
    'generator': {
        'type': 'adam',
        'lr': 2e-4,
        'betas': (0.5, 0.999),
        'weight_decay': 1e-4,
        'eps': 1e-8,
    },
    
    'discriminator': {
        'type': 'adam', 
        'lr': 1e-4,
        'betas': (0.5, 0.999),
        'weight_decay': 1e-4,
        'eps': 1e-8,
    },
    
    'forward_model': {
        'type': 'adam',
        'lr': 1e-4,
        'betas': (0.9, 0.999),
        'weight_decay': 1e-4,
        'eps': 1e-8,
    }
}

# --- 9. è¯„ä¼°ç›®æ ‡ ---
EVALUATION_TARGETS = {
    'forward_network': {
        'spectrum_r2_target': 0.9,                    # å…‰è°±é¢„æµ‹RÂ²ç›®æ ‡
        'metrics_r2_target': 0.9,                     # æŒ‡æ ‡é¢„æµ‹RÂ²ç›®æ ‡
    },
    
    'pigan': {
        'parameter_r2_target': 0.85,                  # å‚æ•°é¢„æµ‹RÂ²ç›®æ ‡
        'discriminator_accuracy_target': 0.85,        # åˆ¤åˆ«å™¨å‡†ç¡®ç‡ç›®æ ‡
    },
    
    'structural_prediction': {
        'violation_rate_target': 0.05,                # è¿çº¦ç‡ç›®æ ‡<5%
        'consistency_score_target': 0.95,             # ä¸€è‡´æ€§åˆ†æ•°ç›®æ ‡>95%
    },
    
    'model_validation': {
        'cycle_consistency_target': 0.005,            # å¾ªç¯ä¸€è‡´æ€§ç›®æ ‡<0.5%
        'stability_target': 0.001,                    # ç¨³å®šæ€§ç›®æ ‡<0.1%
        'plausibility_target': 0.9,                   # ç‰©ç†åˆç†æ€§ç›®æ ‡>90%
    }
}

# --- 10. è®­ç»ƒç›‘æ§ ---
MONITORING_CONFIG = {
    'tensorboard_logging': True,                     # TensorBoardæ—¥å¿—
    'wandb_logging': False,                          # Weights & Biasesæ—¥å¿—
    'checkpoint_frequency': 20,                      # æ£€æŸ¥ç‚¹é¢‘ç‡
    'plot_frequency': 50,                            # ç»˜å›¾é¢‘ç‡
    'evaluation_frequency': 10,                      # è¯„ä¼°é¢‘ç‡
    'early_stopping_patience': 30,                   # æ—©åœè€å¿ƒ
    'save_best_only': True,                          # åªä¿å­˜æœ€ä¼˜æ¨¡å‹
}

# =============================================================================
# å¯¼å‡ºä¼˜åŒ–é…ç½®
# =============================================================================

def get_optimization_config():
    """è·å–å®Œæ•´çš„ä¼˜åŒ–é…ç½®"""
    return {
        'forward_model': FORWARD_MODEL_OPTIMIZATION,
        'generator': GENERATOR_OPTIMIZATION,
        'discriminator': DISCRIMINATOR_OPTIMIZATION,
        'constraints': CONSTRAINT_OPTIMIZATION,
        'training': TRAINING_OPTIMIZATION,
        'loss_weights': LOSS_WEIGHTS,
        'model_architecture': MODEL_ARCHITECTURE,
        'optimizer': OPTIMIZER_CONFIG,
        'evaluation_targets': EVALUATION_TARGETS,
        'monitoring': MONITORING_CONFIG,
    }

def print_optimization_summary():
    """æ‰“å°ä¼˜åŒ–é…ç½®æ‘˜è¦"""
    print("="*60)
    print("PI-GAN ä¼˜åŒ–é…ç½®æ‘˜è¦")
    print("="*60)
    print("ğŸ¯ ä¼˜åŒ–ç›®æ ‡:")
    print(f"  - å‰å‘ç½‘ç»œå…‰è°±é¢„æµ‹RÂ²: 0.50 â†’ 0.90")
    print(f"  - PI-GANå‚æ•°é¢„æµ‹RÂ²: 0.53 â†’ 0.85") 
    print(f"  - åˆ¤åˆ«å™¨å‡†ç¡®ç‡: 0.61 â†’ 0.85")
    print(f"  - å‚æ•°è¿çº¦ç‡: 87.4% â†’ <5%")
    print(f"  - ç‰©ç†åˆç†æ€§: 0.13 â†’ 0.90")
    print("")
    print("ğŸ”§ ä¸»è¦æ”¹è¿›:")
    print("  - å¢å¼ºç½‘ç»œæ¶æ„å’Œå®¹é‡")
    print("  - ä¼˜åŒ–æŸå¤±å‡½æ•°æƒé‡")
    print("  - åŠ å¼ºå‚æ•°çº¦æŸæœºåˆ¶")
    print("  - æ”¹è¿›è®­ç»ƒç­–ç•¥")
    print("  - æ·»åŠ ç‰©ç†çº¦æŸæŸå¤±")
    print("="*60)

if __name__ == "__main__":
    print_optimization_summary()